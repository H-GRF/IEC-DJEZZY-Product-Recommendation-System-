{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8378411,"sourceType":"datasetVersion","datasetId":4982097}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#####\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\ntrain = pd.read_csv('/kaggle/input/djezzy/new_trainDjezzy.csv')\ntest = pd.read_csv('/kaggle/input/djezzy/TestDJEZZY.csv')\ntrain['SUBSCRIPTION_DATE'] = pd.to_datetime(train['SUBSCRIPTION_DATE'])\ntrain['USAGE_DATE'] = pd.to_datetime(train['USAGE_DATE'])\ntest['SUBSCRIPTION_DATE'] = pd.to_datetime(test['SUBSCRIPTION_DATE'])\ntest['USAGE_DATE'] = pd.to_datetime(test['USAGE_DATE'])\n\nX_train = train.drop(['Product_ID', 'SUBSCRIPTION_DATE', 'subscribers'], axis=1)\ny_train = train['Product_ID']\nX_test = test.drop(['SUBSCRIPTION_DATE', 'USAGE_DATE', 'subscribers'], axis=1)\ncategorical_features = ['usage_Type', 'Destination']\nnumerical_features = ['Amount_DZD', 'Amount_data_DZD', 'Volume_Data_KB', 'Volume_KB_SC_Nbr', 'Nb_USAGE']\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n    ])\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n])\npipeline.fit(X_train, y_train)\npredicted_product_ids = pipeline.predict(test)\nsubmission = pd.DataFrame({\n    'subscribers': test['subscribers'],\n    'Product_ID': predicted_product_ids\n})\nif submission['subscribers'].duplicated().any():\n    print(\"Duplicates found. Aggregating predictions...\")\n    submission = submission.groupby('subscribers')['Product_ID'].agg(lambda x: x.mode()[0]).reset_index()\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully! No duplicates found.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-10T20:19:30.310719Z","iopub.execute_input":"2024-05-10T20:19:30.311031Z","iopub.status.idle":"2024-05-10T20:20:17.795405Z","shell.execute_reply.started":"2024-05-10T20:19:30.311001Z","shell.execute_reply":"2024-05-10T20:20:17.794237Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Duplicates found. Aggregating predictions...\nSubmission file created successfully! No duplicates found.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\ntrain = pd.read_csv('/kaggle/input/djezzy/new_trainDjezzy.csv')\ntest = pd.read_csv('/kaggle/input/djezzy/TestDJEZZY.csv')\ntrain['SUBSCRIPTION_DATE'] = pd.to_datetime(train['SUBSCRIPTION_DATE'])\ntrain['USAGE_DATE'] = pd.to_datetime(train['USAGE_DATE'])\ntrain['Month'] = train['SUBSCRIPTION_DATE'].dt.month\nX = train.drop(['Product_ID', 'SUBSCRIPTION_DATE', 'subscribers'], axis=1)\ny = train['Product_ID']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=42)  # 20% for validation\ncategorical_features = ['usage_Type', 'Destination']\nnumerical_features = ['Amount_DZD', 'Amount_data_DZD', 'Volume_Data_KB', 'Volume_KB_SC_Nbr', 'Nb_USAGE']\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n    ])\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n])\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nprint(f'Accuracy: {accuracy * 100:.2f}%')\nX_test = test.drop(['SUBSCRIPTION_DATE',, 'subscribers'], axis=1)\npredicted_product_ids = pipeline.predict(X_test)\nsubmission = pd.DataFrame({\n    'subscribers': test['subscribers'], \n    'Product_ID': predicted_product_ids\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\ntrain = pd.read_csv('/kaggle/input/djezzy/new_trainDjezzy.csv')\ntrain['SUBSCRIPTION_DATE'] = pd.to_datetime(train['SUBSCRIPTION_DATE'])\ntrain['USAGE_DATE'] = pd.to_datetime(train['USAGE_DATE'])\ntrain['Month'] = train['SUBSCRIPTION_DATE'].dt.month\nX = train.drop(['Product_ID', 'SUBSCRIPTION_DATE','USAGE_DATE', 'subscribers','Ines'], axis=1)\ny = train['Product_ID']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\ncategorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\nnumerical_features = X_train.select_dtypes(include=['int', 'float']).columns.tolist()\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n    ],    remainder='passthrough')\nX_train_preprocessed = preprocessor.fit_transform(X_train)\nX_val_preprocessed = preprocessor.transform(X_val)\nencoder = LabelEncoder()\ny_train_encoded = encoder.fit_transform(y_train)\ny_val_encoded = encoder.transform(y_val)\nmodel = Sequential([\n    Input(shape=(X_train_preprocessed.shape[1],)),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(len(encoder.classes_), activation='softmax')  \n])\nmodel.compile(optimizer=Adam(learning_rate=0.001), \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\nhistory = model.fit(X_train_preprocessed, y_train_encoded, \n                    epochs=20, \n                    validation_data=(X_val_preprocessed, y_val_encoded))\ntest = pd.read_csv('/kaggle/input/djezzy/TestDJEZZY.csv')\ntest['SUBSCRIPTION_DATE'] = pd.to_datetime(test['SUBSCRIPTION_DATE'])\ntest['USAGE_DATE'] = pd.to_datetime(test['USAGE_DATE'])\ntest['Month'] = test['SUBSCRIPTION_DATE'].dt.month\nX_test = test.drop(['SUBSCRIPTION_DATE', 'USAGE_DATE', 'subscribers'], axis=1)\nX_test_preprocessed = preprocessor.transform(X_test)\ntest_predictions = model.predict(X_test_preprocessed)\ntest_predicted_labels = encoder.inverse_transform(test_predictions.argmax(axis=1))\nsubmission = pd.DataFrame({\n    'subscribers': test['subscribers'],\n    'Product_ID': test_predicted_labels\n})\nsubmission = submission.drop_duplicates(subset=['subscribers'])\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#####\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\ntrain = pd.read_csv('/kaggle/input/djezzy/new_trainDjezzy.csv')\ntest = pd.read_csv('/kaggle/input/djezzy/TestDJEZZY.csv')\ntrain['SUBSCRIPTION_DATE'] = pd.to_datetime(train['SUBSCRIPTION_DATE'])\ntrain['USAGE_DATE'] = pd.to_datetime(train['USAGE_DATE'])\ntest['SUBSCRIPTION_DATE'] = pd.to_datetime(test['SUBSCRIPTION_DATE'])\ntest['USAGE_DATE'] = pd.to_datetime(test['USAGE_DATE'])\ntrain = train.drop(['Ines'])","metadata":{"execution":{"iopub.status.busy":"2024-05-10T21:35:04.532270Z","iopub.status.idle":"2024-05-10T21:35:04.533028Z","shell.execute_reply.started":"2024-05-10T21:35:04.532770Z","shell.execute_reply":"2024-05-10T21:35:04.532794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train ","metadata":{"execution":{"iopub.status.busy":"2024-05-10T21:35:04.534483Z","iopub.status.idle":"2024-05-10T21:35:04.535260Z","shell.execute_reply.started":"2024-05-10T21:35:04.534978Z","shell.execute_reply":"2024-05-10T21:35:04.535002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train = train.drop(['Product_ID', 'SUBSCRIPTION_DATE', 'subscribers'], axis=1)\ny_train = train['Product_ID']\nX_test = test.drop(['SUBSCRIPTION_DATE', 'USAGE_DATE', 'subscribers'], axis=1)\ncategorical_features = ['usage_Type', 'Destination']\nnumerical_features = ['Amount_DZD', 'Amount_data_DZD', 'Volume_Data_KB', 'Volume_KB_SC_Nbr', 'Nb_USAGE']\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n    ])\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n])\npipeline.fit(X_train, y_train)\npredicted_product_ids = pipeline.predict(test)\nsubmission = pd.DataFrame({\n    'subscribers': test['subscribers'],\n    'Product_ID': predicted_product_ids\n})\nif submission['subscribers'].duplicated().any():\n    print(\"Duplicates found. Aggregating predictions...\")\n    submission = submission.groupby('subscribers')['Product_ID'].agg(lambda x: x.mode()[0]).reset_index()\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully! No duplicates found.\")","metadata":{},"execution_count":null,"outputs":[]}]}